{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangExtract + Azure OpenAI: Quickstart\n",
        "\n",
        "This notebook shows a minimal example of using the `langextract-azureopenai` provider.\n",
        "\n",
        "Prerequisites:\n",
        "- Install the package (editable is fine): `pip install -e .` from the project root\n",
        "- Set credentials in your environment:\n",
        "  - `export AZURE_OPENAI_API_KEY=\"<your-key>\"`\n",
        "  - `export AZURE_OPENAI_ENDPOINT=\"https://<your-endpoint>.openai.azure.com/\"`\n",
        "  - `export AZURE_OPENAI_API_VERSION=\"2024-02-15-preview\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "db3f0d2a",
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Please set AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, and AZURE_OPENAI_API_VERSION before running.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Validate credentials\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endpoint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_version:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     15\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mPlease set AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, and AZURE_OPENAI_API_VERSION before running.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     16\u001b[39m     )\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m✅ Credentials detected\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mRuntimeError\u001b[39m: Please set AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, and AZURE_OPENAI_API_VERSION before running."
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import langextract as lx\n",
        "\n",
        "# Ensure the provider class is importable and registered\n",
        "from langextract_azureopenai import AzureOpenAILanguageModel  # noqa\n",
        "\n",
        "# Read credentials from environment (recommended)\n",
        "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
        "endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
        "api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
        "# Validate credentials\n",
        "if not api_key or not endpoint or not api_version:\n",
        "    raise RuntimeError(\n",
        "        'Please set AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, and AZURE_OPENAI_API_VERSION before running.'\n",
        "    )\n",
        "\n",
        "print('✅ Credentials detected')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97653de8",
      "metadata": {},
      "source": [
        "## Simple Chat Completion\n",
        "\n",
        "Create a provider via LangExtract's factory and run a basic prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aba7df1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Created provider: AzureOpenAILanguageModel\n",
            "Hello from Azure OpenAI! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "config = lx.factory.ModelConfig(\n",
        "    model_id='azureopenai-gpt-4.1',\n",
        "    provider='AzureOpenAILanguageModel',\n",
        "    provider_kwargs={\n",
        "        'api_key': api_key,\n",
        "        'azure_endpoint': endpoint,\n",
        "        'api_version': api_version,\n",
        "    },\n",
        ")\n",
        "model = lx.factory.create_model(config)\n",
        "print(f'✓ Created provider: {type(model).__name__}')\n",
        "\n",
        "prompts = ['Say hello from Azure OpenAI.']\n",
        "results = list(model.infer(prompts))\n",
        "print(results[0][0].output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce8d8c25",
      "metadata": {},
      "source": [
        "## Structured Extraction (Optional)\n",
        "\n",
        "A minimal extraction example using `lx.extract` with examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd36822",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/35/j3z165c92v57rwbh03pn5pk80000gn/T/ipykernel_57068/1402652278.py:25: UserWarning: With 'config', schema constraints are still applied via examples. Or pass explicit schema in config.provider_kwargs.\n",
            "  result = lx.extract(\n",
            "2025-08-19 09:54:01,498 - langextract.debug - DEBUG - [langextract.inference] CALL: BaseLanguageModel.__init__(self=<AzureOpenAILanguageModel>, constraint=None, kwargs={})\n",
            "2025-08-19 09:54:01,498 - langextract.debug - DEBUG - [langextract.inference] RETURN: BaseLanguageModel.__init__ -> None (0.0 ms)\n",
            "2025-08-19 09:54:01,519 - langextract.debug - DEBUG - [langextract.inference] CALL: BaseLanguageModel.apply_schema(self=<AzureOpenAILanguageModel>, schema_instance=<langextract_...t 0x10e441940>)\n",
            "2025-08-19 09:54:01,519 - langextract.debug - DEBUG - [langextract.inference] RETURN: BaseLanguageModel.apply_schema -> None (0.0 ms)\n",
            "DEBUG:absl:Initialized Annotator with prompt:\n",
            "Extract people, organizations, and locations from the text.\n",
            "\n",
            "Examples\n",
            "Q: John Smith works at Microsoft in Seattle.\n",
            "A: {\n",
            "  \"extractions\": [\n",
            "    {\n",
            "      \"person\": \"John Smith\",\n",
            "      \"person_attributes\": {\n",
            "        \"role\": \"employee\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"organization\": \"Microsoft\",\n",
            "      \"organization_attributes\": {\n",
            "        \"type\": \"company\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"location\": \"Seattle\",\n",
            "      \"location_attributes\": {\n",
            "        \"type\": \"city\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "Q: \n",
            "A: \n",
            "INFO:absl:Starting document annotation.\n",
            "\u001b[94m\u001b[1mLangExtract\u001b[0m: model=\u001b[92mazureopenai-gpt-4.1\u001b[0m [00:00]2025-08-19 09:54:01,534 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='Sarah Johnson is the CEO of TechCorp in San Francisco.')\n",
            "2025-08-19 09:54:01,534 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.2 ms)\n",
            "INFO:absl:Processing batch 0 with length 1\n",
            "DEBUG:absl:Token util returns string: Sarah Johnson is the CEO of TechCorp in San Francisco. for tokenized_text: TokenizedText(text='Sarah Johnson is the CEO of TechCorp in San Francisco.', tokens=[Token(index=0, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=0, end_pos=5), first_token_after_newline=False), Token(index=1, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=6, end_pos=13), first_token_after_newline=False), Token(index=2, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=14, end_pos=16), first_token_after_newline=False), Token(index=3, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=17, end_pos=20), first_token_after_newline=False), Token(index=4, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=21, end_pos=24), first_token_after_newline=False), Token(index=5, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=25, end_pos=27), first_token_after_newline=False), Token(index=6, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=28, end_pos=36), first_token_after_newline=False), Token(index=7, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=37, end_pos=39), first_token_after_newline=False), Token(index=8, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=40, end_pos=43), first_token_after_newline=False), Token(index=9, token_type=<TokenType.WORD: 0>, char_interval=CharInterval(start_pos=44, end_pos=53), first_token_after_newline=False), Token(index=10, token_type=<TokenType.PUNCTUATION: 2>, char_interval=CharInterval(start_pos=53, end_pos=54), first_token_after_newline=False)]), token_interval: TokenInterval(start_index=0, end_index=11)\n",
            "\u001b[94m\u001b[1mLangExtract\u001b[0m: model=\u001b[92mazureopenai-gpt-4.1\u001b[0m, current=\u001b[92m54\u001b[0m chars, processed=\u001b[92m54\u001b[0m chars:  [00:00]DEBUG:absl:Processing chunk: TextChunk(\n",
            "  interval=[start_index: 0, end_index: 11],\n",
            "  Document ID: doc_fdd4f06a,\n",
            "  Chunk Text: 'Sarah Johnson is the CEO of TechCorp in San Francisco.'\n",
            ")\n",
            "DEBUG:absl:Top inference result: {\n",
            "  \"extractions\": [\n",
            "    {\n",
            "      \"person\": \"Sarah Johnson\",\n",
            "      \"person_attributes\": {\n",
            "        \"role\": \"CEO\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"organization\": \"TechCorp\",\n",
            "      \"organization_attributes\": {\n",
            "        \"type\": \"company\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"location\": \"San Francisco\",\n",
            "      \"location_attributes\": {\n",
            "        \"type\": \"city\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "INFO:absl:Starting resolver process for input text.\n",
            "DEBUG:absl:Input Text: {\n",
            "  \"extractions\": [\n",
            "    {\n",
            "      \"person\": \"Sarah Johnson\",\n",
            "      \"person_attributes\": {\n",
            "        \"role\": \"CEO\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"organization\": \"TechCorp\",\n",
            "      \"organization_attributes\": {\n",
            "        \"type\": \"company\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"location\": \"San Francisco\",\n",
            "      \"location_attributes\": {\n",
            "        \"type\": \"city\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "INFO:absl:Starting string parsing.\n",
            "DEBUG:absl:input_string: {\n",
            "  \"extractions\": [\n",
            "    {\n",
            "      \"person\": \"Sarah Johnson\",\n",
            "      \"person_attributes\": {\n",
            "        \"role\": \"CEO\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"organization\": \"TechCorp\",\n",
            "      \"organization_attributes\": {\n",
            "        \"type\": \"company\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"location\": \"San Francisco\",\n",
            "      \"location_attributes\": {\n",
            "        \"type\": \"city\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "DEBUG:absl:Successfully parsed content.\n",
            "INFO:absl:Completed parsing of string.\n",
            "DEBUG:absl:Parsed content: [{'person': 'Sarah Johnson', 'person_attributes': {'role': 'CEO'}}, {'organization': 'TechCorp', 'organization_attributes': {'type': 'company'}}, {'location': 'San Francisco', 'location_attributes': {'type': 'city'}}]\n",
            "INFO:absl:Starting to extract and order extractions from data.\n",
            "INFO:absl:Completed extraction and ordering of extractions.\n",
            "DEBUG:absl:Completed the resolver process.\n",
            "INFO:absl:Starting alignment process for provided chunk text.\n",
            "DEBUG:absl:WordAligner: Starting alignment of extractions with the source text. Extraction groups to align: [[Extraction(extraction_class='person', extraction_text='Sarah Johnson', char_interval=None, alignment_status=None, extraction_index=1, group_index=0, description=None, attributes={'role': 'CEO'}), Extraction(extraction_class='organization', extraction_text='TechCorp', char_interval=None, alignment_status=None, extraction_index=2, group_index=1, description=None, attributes={'type': 'company'}), Extraction(extraction_class='location', extraction_text='San Francisco', char_interval=None, alignment_status=None, extraction_index=3, group_index=2, description=None, attributes={'type': 'city'})]]\n",
            "2025-08-19 09:54:02,517 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='Sarah Johnson is the CEO of TechCorp in San Francisco.')\n",
            "2025-08-19 09:54:02,517 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.1 ms)\n",
            "2025-08-19 09:54:02,518 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='␟')\n",
            "2025-08-19 09:54:02,518 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.0 ms)\n",
            "DEBUG:absl:Using delimiter '␟' for extraction alignment\n",
            "2025-08-19 09:54:02,519 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='Sarah Johnson ␟ TechCorp ␟ San Francisco')\n",
            "2025-08-19 09:54:02,519 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.1 ms)\n",
            "DEBUG:absl:Processing extraction group 0 with 3 extractions.\n",
            "2025-08-19 09:54:02,520 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='Sarah Johnson')\n",
            "2025-08-19 09:54:02,520 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.0 ms)\n",
            "2025-08-19 09:54:02,521 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='TechCorp')\n",
            "2025-08-19 09:54:02,521 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.0 ms)\n",
            "2025-08-19 09:54:02,521 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='San Francisco')\n",
            "2025-08-19 09:54:02,521 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.0 ms)\n",
            "2025-08-19 09:54:02,522 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='Sarah Johnson is the CEO of TechCorp in San Francisco.')\n",
            "2025-08-19 09:54:02,522 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.0 ms)\n",
            "2025-08-19 09:54:02,522 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='Sarah Johnson')\n",
            "2025-08-19 09:54:02,523 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.0 ms)\n",
            "2025-08-19 09:54:02,523 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='TechCorp')\n",
            "2025-08-19 09:54:02,523 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.0 ms)\n",
            "2025-08-19 09:54:02,523 - langextract.debug - DEBUG - [langextract.tokenizer] CALL: tokenize(text='San Francisco')\n",
            "2025-08-19 09:54:02,524 - langextract.debug - DEBUG - [langextract.tokenizer] RETURN: tokenize -> TokenizedText...wline=False)]) (0.0 ms)\n",
            "DEBUG:absl:Final aligned extraction groups: [[Extraction(extraction_class='person', extraction_text='Sarah Johnson', char_interval=CharInterval(start_pos=0, end_pos=13), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=1, group_index=0, description=None, attributes={'role': 'CEO'}), Extraction(extraction_class='organization', extraction_text='TechCorp', char_interval=CharInterval(start_pos=28, end_pos=36), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=2, group_index=1, description=None, attributes={'type': 'company'}), Extraction(extraction_class='location', extraction_text='San Francisco', char_interval=CharInterval(start_pos=40, end_pos=53), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=3, group_index=2, description=None, attributes={'type': 'city'})]]\n",
            "DEBUG:absl:Aligned extractions count: 3\n",
            "DEBUG:absl:Yielding aligned extraction: Extraction(extraction_class='person', extraction_text='Sarah Johnson', char_interval=CharInterval(start_pos=0, end_pos=13), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=1, group_index=0, description=None, attributes={'role': 'CEO'})\n",
            "DEBUG:absl:Yielding aligned extraction: Extraction(extraction_class='organization', extraction_text='TechCorp', char_interval=CharInterval(start_pos=28, end_pos=36), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=2, group_index=1, description=None, attributes={'type': 'company'})\n",
            "DEBUG:absl:Yielding aligned extraction: Extraction(extraction_class='location', extraction_text='San Francisco', char_interval=CharInterval(start_pos=40, end_pos=53), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=3, group_index=2, description=None, attributes={'type': 'city'})\n",
            "INFO:absl:Completed alignment process for the provided source_text.\n",
            "\u001b[94m\u001b[1mLangExtract\u001b[0m: model=\u001b[92mazureopenai-gpt-4.1\u001b[0m, current=\u001b[92m54\u001b[0m chars, processed=\u001b[92m54\u001b[0m chars:  [00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m✓\u001b[0m Extraction processing complete\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "INFO:absl:Finalizing annotation for document ID doc_fdd4f06a.\n",
            "INFO:absl:Document annotation completed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m✓\u001b[0m Extracted \u001b[1m3\u001b[0m entities (\u001b[1m3\u001b[0m unique types)\n",
            "  \u001b[96m•\u001b[0m Time: \u001b[1m1.01s\u001b[0m\n",
            "  \u001b[96m•\u001b[0m Speed: \u001b[1m54\u001b[0m chars/sec\n",
            "  \u001b[96m•\u001b[0m Chunks: \u001b[1m1\u001b[0m\n",
            "person -> Sarah Johnson {'role': 'CEO'}\n",
            "organization -> TechCorp {'type': 'company'}\n",
            "location -> San Francisco {'type': 'city'}\n"
          ]
        }
      ],
      "source": [
        "prompt = 'Extract people, organizations, and locations from the text.'\n",
        "examples = [\n",
        "    lx.data.ExampleData(\n",
        "        text='John Smith works at Microsoft in Seattle.',\n",
        "        extractions=[\n",
        "            lx.data.Extraction(extraction_class='person', extraction_text='John Smith', attributes={'role': 'employee'}),\n",
        "            lx.data.Extraction(extraction_class='organization', extraction_text='Microsoft', attributes={'type': 'company'}),\n",
        "            lx.data.Extraction(extraction_class='location', extraction_text='Seattle', attributes={'type': 'city'}),\n",
        "        ],\n",
        "    )\n",
        "]\n",
        "\n",
        "text = 'Sarah Johnson is the CEO of TechCorp in San Francisco.'\n",
        "# Use explicit config to pass credentials in a library-compatible way\n",
        "config2 = lx.factory.ModelConfig(\n",
        "    model_id='azureopenai-gpt-4.1',\n",
        "    provider='AzureOpenAILanguageModel',\n",
        "    provider_kwargs={\n",
        "        'api_key': api_key,\n",
        "        'azure_endpoint': endpoint,\n",
        "        'api_version': api_version,\n",
        "    },\n",
        ")\n",
        "\n",
        "result = lx.extract(\n",
        "    text_or_documents=text,\n",
        "    prompt_description=prompt,\n",
        "    examples=examples,\n",
        "    config=config2,\n",
        ")\n",
        "for e in result.extractions:\n",
        "    print(e.extraction_class, '->', e.extraction_text, e.attributes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0520f19c",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langextract-azureopenai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
